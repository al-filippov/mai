{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7915f17e",
   "metadata": {},
   "source": [
    "### Инициализация Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560de685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d07c7a",
   "metadata": {},
   "source": [
    "#### Загрузка набора данных для задачи классификации\n",
    "\n",
    "В данном примере используется фрагмент набора  данных Cats and Dogs Classification Dataset\n",
    "\n",
    "В наборе данных два класса: кошки и собаки\n",
    "\n",
    "Ссылка: https://www.kaggle.com/datasets/bhavikjikadara/dog-and-cat-classification-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24dd788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "path = kagglehub.dataset_download(\"bhavikjikadara/dog-and-cat-classification-dataset\")\n",
    "path = os.path.join(path, \"PetImages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85652835",
   "metadata": {},
   "source": [
    "#### Формирование выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68de944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 4998 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Cat': 0, 'Dog': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "data_loader = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "train = data_loader.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=9,\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "valid = data_loader.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"binary\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=9,\n",
    "    subset=\"validation\",\n",
    ")\n",
    "\n",
    "train.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb9434d",
   "metadata": {},
   "source": [
    "### Пример переноса обучения с использованием предобученной модели VGGNet19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32c572",
   "metadata": {},
   "source": [
    "Загрузка предобученной модели и отключение обучения для ее слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f1ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.api.applications.vgg19 import VGG19\n",
    "\n",
    "vgg19 = VGG19(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3), pooling=None)\n",
    "\n",
    "vgg19.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250d20b",
   "metadata": {},
   "source": [
    "#### Проектирование архитектуры ИНС на основе предобученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "904b01b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ vgg19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flattened (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,089</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ vgg19 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m20,024,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flattened (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m25,089\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,049,473</span> (76.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,049,473\u001b[0m (76.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,089</span> (98.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,089\u001b[0m (98.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> (76.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,024,384\u001b[0m (76.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dropout, Flatten, Dense\n",
    "\n",
    "tl_model = Sequential()\n",
    "tl_model.add(vgg19)\n",
    "\n",
    "# Добавление собственных слоев (в них будет проводиться обучение для текущей задачи)\n",
    "tl_model.add(Flatten(name=\"flattened\"))\n",
    "tl_model.add(Dropout(0.5, name=\"dropout\"))\n",
    "tl_model.add(Dense(1, activation=\"sigmoid\", name=\"predictions\"))\n",
    "\n",
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fceead",
   "metadata": {},
   "source": [
    "#### Обучение глубокой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe650631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Python\\mai\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 81/313\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39:00\u001b[0m 10s/step - accuracy: 0.8458 - loss: 1.7957"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Python\\mai\\.venv\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/313\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m35:19\u001b[0m 10s/step - accuracy: 0.8594 - loss: 1.6413"
     ]
    }
   ],
   "source": [
    "tl_model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "tl_model.fit(x=train, validation_data=valid, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831795e",
   "metadata": {},
   "source": [
    "#### Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_model.evaluate(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad04a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mahotas as mh\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cat = mh.imread(\"data/-cat.jpg\")\n",
    "plt.imshow(cat)\n",
    "plt.show()\n",
    "\n",
    "dog = mh.imread(\"data/-dog.jpg\")\n",
    "plt.imshow(dog)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e33697",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_cat = mh.resize.resize_rgb_to(cat, (224, 224))\n",
    "\n",
    "resized_dog = mh.resize.resize_rgb_to(dog, (224, 224))\n",
    "resized_dog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "        1\n",
    "        if alexnet_model.predict(item.reshape(1, 224, 224, 3).astype(\"float32\"))\n",
    "        > 0.5\n",
    "        else 0\n",
    "        for item in [resized_cat, resized_dog]\n",
    "]\n",
    "\n",
    "for result in results:\n",
    "    display(result, list(valid.class_indices.keys())[list(valid.class_indices.values()).index(result)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
