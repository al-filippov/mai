{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7915f17e",
   "metadata": {},
   "source": [
    "### Инициализация Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560de685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "import keras\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d07c7a",
   "metadata": {},
   "source": [
    "#### Загрузка набора данных для задачи классификации\n",
    "\n",
    "В данном примере используется фрагмент набора  данных Cats and Dogs Classification Dataset\n",
    "\n",
    "В наборе данных два класса: кошки и собаки\n",
    "\n",
    "Ссылка: https://www.kaggle.com/datasets/bhavikjikadara/dog-and-cat-classification-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24dd788e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 312475648 bytes (500272489 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/bhavikjikadara/dog-and-cat-classification-dataset?dataset_version_number=1 (312475648/812748137) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 775M/775M [01:03<00:00, 7.86MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/user/.cache/kagglehub/datasets/bhavikjikadara/dog-and-cat-classification-dataset/versions/1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"bhavikjikadara/dog-and-cat-classification-dataset\")\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85652835",
   "metadata": {},
   "source": [
    "#### Формирование выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f68de944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19999 images belonging to 1 classes.\n",
      "Found 4999 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "data_loader = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "train = data_loader.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=9,\n",
    "    subset=\"training\",\n",
    ")\n",
    "\n",
    "valid = data_loader.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=9,\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb9434d",
   "metadata": {},
   "source": [
    "### Архитектура AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250d20b",
   "metadata": {},
   "source": [
    "#### Проектирование архитектуры AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904b01b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-04-26 01:27:15,424:jax._src.xla_bridge:1018: Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1745616435.424692 2474885 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1745616435.449215 2474885 service.cc:145] XLA service 0x15fe0b760 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745616435.449229 2474885 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1745616435.451710 2474885 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1745616435.451728 2474885 mps_client.cc:384] XLA backend will use up to 28990554112 bytes on device 0 for SimpleAllocator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M3 Pro\n",
      "\n",
      "systemMemory: 36.00 GB\n",
      "maxCacheSize: 13.50 GB\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,576,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,194</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m34,944\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │           \u001b[38;5;34m384\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m614,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │       \u001b[38;5;34m885,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │     \u001b[38;5;34m1,327,488\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m384\u001b[0m)      │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │     \u001b[38;5;34m1,576,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m8,194\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,821,698</span> (83.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,821,698\u001b[0m (83.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,820,226</span> (83.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,820,226\u001b[0m (83.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> (5.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,472\u001b[0m (5.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import InputLayer, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "\n",
    "alexnet_model = Sequential()\n",
    "\n",
    "# Входной слой\n",
    "alexnet_model.add(InputLayer(shape=(224, 224, 3)))\n",
    "\n",
    "# Первый скрытый слой\n",
    "alexnet_model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation=\"relu\"))\n",
    "alexnet_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "alexnet_model.add(BatchNormalization())\n",
    "\n",
    "# Второй скрытый слой\n",
    "alexnet_model.add(Conv2D(256, kernel_size=(5, 5), activation=\"relu\"))\n",
    "alexnet_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "alexnet_model.add(BatchNormalization())\n",
    "\n",
    "# Третий скрытый слой\n",
    "alexnet_model.add(Conv2D(256, kernel_size=(3, 3), activation=\"relu\"))\n",
    "\n",
    "# Четвертый скрытый слой\n",
    "alexnet_model.add(Conv2D(384, kernel_size=(3, 3), activation=\"relu\"))\n",
    "\n",
    "# Пятый скрытый слой\n",
    "alexnet_model.add(Conv2D(384, kernel_size=(3, 3), activation=\"relu\"))\n",
    "alexnet_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "alexnet_model.add(BatchNormalization())\n",
    "\n",
    "# Шестой скрытый слой\n",
    "alexnet_model.add(Flatten())\n",
    "alexnet_model.add(Dense(4096, activation=\"tanh\"))\n",
    "alexnet_model.add(Dropout(0.5))\n",
    "\n",
    "# Седьмой скрытый слой\n",
    "alexnet_model.add(Dense(4096, activation=\"tanh\"))\n",
    "alexnet_model.add(Dropout(0.5))\n",
    "\n",
    "# Выходной слой\n",
    "alexnet_model.add(Dense(len(train.class_indices), activation=\"softmax\"))\n",
    "\n",
    "alexnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fceead",
   "metadata": {},
   "source": [
    "#### Обучение глубокой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe650631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Projects/python/mai/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Projects/python/mai/.venv/lib/python3.12/site-packages/jax/_src/interpreters/mlir.py:1153: UserWarning: Some donated buffers were not usable: ShapedArray(float32[11,11,3,96]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[5,5,96,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,384]), ShapedArray(float32[384]), ShapedArray(float32[3,3,384,384]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(float32[384,4096]), ShapedArray(float32[4096]), ShapedArray(float32[4096,4096]), ShapedArray(float32[4096]), ShapedArray(float32[4096,2]), ShapedArray(float32[2]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(uint32[2]), ShapedArray(uint32[2]), ShapedArray(int32[]), ShapedArray(float32[]), ShapedArray(float32[11,11,3,96]), ShapedArray(float32[11,11,3,96]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[5,5,96,256]), ShapedArray(float32[5,5,96,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,256]), ShapedArray(float32[3,3,256,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,384]), ShapedArray(float32[3,3,256,384]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(float32[3,3,384,384]), ShapedArray(float32[3,3,384,384]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(float32[384,4096]), ShapedArray(float32[384,4096]), ShapedArray(float32[4096]), ShapedArray(float32[4096]), ShapedArray(float32[4096,4096]), ShapedArray(float32[4096,4096]), ShapedArray(float32[4096]), ShapedArray(float32[4096]), ShapedArray(float32[4096,2]), ShapedArray(float32[4096,2]), ShapedArray(float32[2]), ShapedArray(float32[2]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]).\n",
      "Donation is not implemented for ('METAL',).\n",
      "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
      "  warnings.warn(\"Some donated buffers were not usable:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m244/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - accuracy: 0.5025 - loss: 3.7129"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Projects/python/mai/.venv/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5027 - loss: 3.2935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Projects/python/mai/.venv/lib/python3.12/site-packages/jax/_src/interpreters/mlir.py:1153: UserWarning: Some donated buffers were not usable: ShapedArray(float32[11,11,3,96]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[5,5,96,256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,256]), ShapedArray(float32[256]), ShapedArray(float32[3,3,256,384]), ShapedArray(float32[384]), ShapedArray(float32[3,3,384,384]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(float32[384,4096]), ShapedArray(float32[4096]), ShapedArray(float32[4096,4096]), ShapedArray(float32[4096]), ShapedArray(float32[4096,2]), ShapedArray(float32[2]), ShapedArray(float32[96]), ShapedArray(float32[96]), ShapedArray(float32[256]), ShapedArray(float32[256]), ShapedArray(float32[384]), ShapedArray(float32[384]), ShapedArray(uint32[2]), ShapedArray(uint32[2]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]), ShapedArray(float32[]).\n",
      "Donation is not implemented for ('METAL',).\n",
      "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
      "  warnings.warn(\"Some donated buffers were not usable:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 129ms/step - accuracy: 0.5027 - loss: 3.2887 - val_accuracy: 0.4960 - val_loss: 0.7563\n",
      "Epoch 2/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 112ms/step - accuracy: 0.5116 - loss: 0.8322 - val_accuracy: 0.5080 - val_loss: 0.9215\n",
      "Epoch 3/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 112ms/step - accuracy: 0.5023 - loss: 0.8604 - val_accuracy: 0.4984 - val_loss: 0.7005\n",
      "Epoch 4/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 112ms/step - accuracy: 0.5046 - loss: 0.8040 - val_accuracy: 0.5194 - val_loss: 0.8496\n",
      "Epoch 5/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.5054 - loss: 0.8219 - val_accuracy: 0.5218 - val_loss: 0.7518\n",
      "Epoch 6/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 109ms/step - accuracy: 0.5146 - loss: 0.8019 - val_accuracy: 0.4766 - val_loss: 0.8985\n",
      "Epoch 7/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 109ms/step - accuracy: 0.5098 - loss: 0.8301 - val_accuracy: 0.4840 - val_loss: 0.7566\n",
      "Epoch 8/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 110ms/step - accuracy: 0.5055 - loss: 0.8197 - val_accuracy: 0.5312 - val_loss: 0.7122\n",
      "Epoch 9/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 110ms/step - accuracy: 0.5118 - loss: 0.8200 - val_accuracy: 0.5300 - val_loss: 0.7078\n",
      "Epoch 10/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 110ms/step - accuracy: 0.5200 - loss: 0.7933 - val_accuracy: 0.5314 - val_loss: 0.7145\n",
      "Epoch 11/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 110ms/step - accuracy: 0.5179 - loss: 0.8879 - val_accuracy: 0.5060 - val_loss: 0.9301\n",
      "Epoch 12/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 110ms/step - accuracy: 0.5383 - loss: 0.8096 - val_accuracy: 0.5164 - val_loss: 0.8153\n",
      "Epoch 13/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 110ms/step - accuracy: 0.5495 - loss: 0.7967 - val_accuracy: 0.5430 - val_loss: 0.7053\n",
      "Epoch 14/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - accuracy: 0.5480 - loss: 0.7701 - val_accuracy: 0.5512 - val_loss: 0.7169\n",
      "Epoch 15/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 110ms/step - accuracy: 0.5360 - loss: 0.7858 - val_accuracy: 0.4928 - val_loss: 0.9038\n",
      "Epoch 16/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 110ms/step - accuracy: 0.5227 - loss: 0.8437 - val_accuracy: 0.5868 - val_loss: 0.6769\n",
      "Epoch 17/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - accuracy: 0.5383 - loss: 0.7971 - val_accuracy: 0.5470 - val_loss: 0.7223\n",
      "Epoch 18/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - accuracy: 0.5457 - loss: 0.7793 - val_accuracy: 0.5292 - val_loss: 0.6964\n",
      "Epoch 19/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 111ms/step - accuracy: 0.5282 - loss: 0.7834 - val_accuracy: 0.4652 - val_loss: 0.7896\n",
      "Epoch 20/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 112ms/step - accuracy: 0.5448 - loss: 0.7837 - val_accuracy: 0.5522 - val_loss: 0.7130\n",
      "Epoch 21/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 112ms/step - accuracy: 0.5500 - loss: 0.8043 - val_accuracy: 0.5368 - val_loss: 0.9107\n",
      "Epoch 22/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.5565 - loss: 0.8091 - val_accuracy: 0.5402 - val_loss: 0.7115\n",
      "Epoch 23/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.5521 - loss: 0.7994 - val_accuracy: 0.5706 - val_loss: 0.7237\n",
      "Epoch 24/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - accuracy: 0.5585 - loss: 0.7796 - val_accuracy: 0.4920 - val_loss: 1.2746\n",
      "Epoch 25/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.5621 - loss: 0.8693 - val_accuracy: 0.6090 - val_loss: 0.7038\n",
      "Epoch 26/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.5771 - loss: 0.7790 - val_accuracy: 0.5122 - val_loss: 0.7697\n",
      "Epoch 27/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.5707 - loss: 0.8019 - val_accuracy: 0.5612 - val_loss: 0.7767\n",
      "Epoch 28/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.6028 - loss: 0.7427 - val_accuracy: 0.6198 - val_loss: 0.6625\n",
      "Epoch 29/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.5992 - loss: 0.7452 - val_accuracy: 0.5364 - val_loss: 0.8801\n",
      "Epoch 30/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.5861 - loss: 0.7703 - val_accuracy: 0.5824 - val_loss: 0.7226\n",
      "Epoch 31/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.5947 - loss: 0.7373 - val_accuracy: 0.5364 - val_loss: 0.7252\n",
      "Epoch 32/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - accuracy: 0.5763 - loss: 0.7515 - val_accuracy: 0.5476 - val_loss: 0.8190\n",
      "Epoch 33/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - accuracy: 0.5899 - loss: 0.7776 - val_accuracy: 0.5826 - val_loss: 0.8061\n",
      "Epoch 34/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.5941 - loss: 0.7876 - val_accuracy: 0.6587 - val_loss: 0.6503\n",
      "Epoch 35/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.6219 - loss: 0.7347 - val_accuracy: 0.6271 - val_loss: 0.7372\n",
      "Epoch 36/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.6346 - loss: 0.7189 - val_accuracy: 0.6050 - val_loss: 0.7036\n",
      "Epoch 37/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.6371 - loss: 0.7221 - val_accuracy: 0.6078 - val_loss: 0.7670\n",
      "Epoch 38/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.6708 - loss: 0.6741 - val_accuracy: 0.7197 - val_loss: 0.6101\n",
      "Epoch 39/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.6848 - loss: 0.6698 - val_accuracy: 0.6543 - val_loss: 0.7570\n",
      "Epoch 40/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7007 - loss: 0.6474 - val_accuracy: 0.6799 - val_loss: 0.6546\n",
      "Epoch 41/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.7170 - loss: 0.6346 - val_accuracy: 0.6855 - val_loss: 0.7528\n",
      "Epoch 42/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.7286 - loss: 0.6106 - val_accuracy: 0.5236 - val_loss: 1.3208\n",
      "Epoch 43/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.7171 - loss: 0.6537 - val_accuracy: 0.5730 - val_loss: 0.9234\n",
      "Epoch 44/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.7254 - loss: 0.6224 - val_accuracy: 0.7397 - val_loss: 0.5314\n",
      "Epoch 45/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.7316 - loss: 0.6053 - val_accuracy: 0.6655 - val_loss: 0.6863\n",
      "Epoch 46/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7249 - loss: 0.6102 - val_accuracy: 0.7515 - val_loss: 0.5204\n",
      "Epoch 47/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7433 - loss: 0.5910 - val_accuracy: 0.7107 - val_loss: 0.6665\n",
      "Epoch 48/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.7644 - loss: 0.5728 - val_accuracy: 0.7591 - val_loss: 0.5306\n",
      "Epoch 49/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7590 - loss: 0.5889 - val_accuracy: 0.7727 - val_loss: 0.4819\n",
      "Epoch 50/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7666 - loss: 0.5494 - val_accuracy: 0.6096 - val_loss: 1.0857\n",
      "Epoch 51/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - accuracy: 0.7607 - loss: 0.6030 - val_accuracy: 0.7719 - val_loss: 0.5350\n",
      "Epoch 52/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7925 - loss: 0.5029 - val_accuracy: 0.7367 - val_loss: 0.6112\n",
      "Epoch 53/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7861 - loss: 0.5090 - val_accuracy: 0.7687 - val_loss: 0.7860\n",
      "Epoch 54/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7825 - loss: 0.5503 - val_accuracy: 0.7143 - val_loss: 0.7477\n",
      "Epoch 55/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.7887 - loss: 0.5271 - val_accuracy: 0.7419 - val_loss: 0.6502\n",
      "Epoch 56/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7956 - loss: 0.5107 - val_accuracy: 0.7507 - val_loss: 0.6501\n",
      "Epoch 57/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8002 - loss: 0.5215 - val_accuracy: 0.8041 - val_loss: 0.4445\n",
      "Epoch 58/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8219 - loss: 0.4553 - val_accuracy: 0.8087 - val_loss: 0.4815\n",
      "Epoch 59/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8172 - loss: 0.4641 - val_accuracy: 0.7937 - val_loss: 0.4943\n",
      "Epoch 60/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8174 - loss: 0.4682 - val_accuracy: 0.8153 - val_loss: 0.5595\n",
      "Epoch 61/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8324 - loss: 0.4343 - val_accuracy: 0.8223 - val_loss: 0.4733\n",
      "Epoch 62/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8341 - loss: 0.4543 - val_accuracy: 0.8201 - val_loss: 0.4177\n",
      "Epoch 63/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8351 - loss: 0.4181 - val_accuracy: 0.8069 - val_loss: 0.4277\n",
      "Epoch 64/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8282 - loss: 0.4466 - val_accuracy: 0.8091 - val_loss: 0.4614\n",
      "Epoch 65/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8460 - loss: 0.3912 - val_accuracy: 0.8289 - val_loss: 0.4737\n",
      "Epoch 66/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8427 - loss: 0.4351 - val_accuracy: 0.7987 - val_loss: 0.5135\n",
      "Epoch 67/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8517 - loss: 0.3976 - val_accuracy: 0.8271 - val_loss: 0.4895\n",
      "Epoch 68/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8680 - loss: 0.3461 - val_accuracy: 0.8285 - val_loss: 0.4383\n",
      "Epoch 69/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8515 - loss: 0.4061 - val_accuracy: 0.8229 - val_loss: 0.4568\n",
      "Epoch 70/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8582 - loss: 0.3778 - val_accuracy: 0.8189 - val_loss: 0.4880\n",
      "Epoch 71/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8615 - loss: 0.3958 - val_accuracy: 0.8625 - val_loss: 0.4214\n",
      "Epoch 72/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8827 - loss: 0.3295 - val_accuracy: 0.7845 - val_loss: 0.6079\n",
      "Epoch 73/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8669 - loss: 0.3731 - val_accuracy: 0.8209 - val_loss: 0.4887\n",
      "Epoch 74/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8799 - loss: 0.3295 - val_accuracy: 0.6437 - val_loss: 1.2445\n",
      "Epoch 75/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8477 - loss: 0.4153 - val_accuracy: 0.8191 - val_loss: 0.4782\n",
      "Epoch 76/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8442 - loss: 0.4269 - val_accuracy: 0.6861 - val_loss: 0.9858\n",
      "Epoch 77/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8568 - loss: 0.3901 - val_accuracy: 0.8039 - val_loss: 0.5898\n",
      "Epoch 78/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8721 - loss: 0.3510 - val_accuracy: 0.8087 - val_loss: 0.6275\n",
      "Epoch 79/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8721 - loss: 0.3651 - val_accuracy: 0.8371 - val_loss: 0.4663\n",
      "Epoch 80/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8718 - loss: 0.3533 - val_accuracy: 0.8149 - val_loss: 0.5178\n",
      "Epoch 81/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8717 - loss: 0.3586 - val_accuracy: 0.8273 - val_loss: 0.4506\n",
      "Epoch 82/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - accuracy: 0.8679 - loss: 0.3603 - val_accuracy: 0.7735 - val_loss: 0.4855\n",
      "Epoch 83/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - accuracy: 0.8640 - loss: 0.3646 - val_accuracy: 0.7855 - val_loss: 0.7322\n",
      "Epoch 84/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8773 - loss: 0.3555 - val_accuracy: 0.8063 - val_loss: 0.7366\n",
      "Epoch 85/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8764 - loss: 0.3502 - val_accuracy: 0.8343 - val_loss: 0.5661\n",
      "Epoch 86/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8889 - loss: 0.3212 - val_accuracy: 0.7271 - val_loss: 1.0910\n",
      "Epoch 87/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8778 - loss: 0.3452 - val_accuracy: 0.8353 - val_loss: 0.4696\n",
      "Epoch 88/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8867 - loss: 0.3206 - val_accuracy: 0.8579 - val_loss: 0.4615\n",
      "Epoch 89/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8974 - loss: 0.2942 - val_accuracy: 0.8341 - val_loss: 0.5915\n",
      "Epoch 90/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8900 - loss: 0.3450 - val_accuracy: 0.8151 - val_loss: 0.8011\n",
      "Epoch 91/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8865 - loss: 0.3417 - val_accuracy: 0.7877 - val_loss: 0.6034\n",
      "Epoch 92/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8887 - loss: 0.3266 - val_accuracy: 0.8595 - val_loss: 0.3694\n",
      "Epoch 93/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8903 - loss: 0.3208 - val_accuracy: 0.8511 - val_loss: 0.4983\n",
      "Epoch 94/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.8997 - loss: 0.2983 - val_accuracy: 0.8713 - val_loss: 0.4641\n",
      "Epoch 95/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.9007 - loss: 0.2928 - val_accuracy: 0.8377 - val_loss: 0.5199\n",
      "Epoch 96/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8989 - loss: 0.3080 - val_accuracy: 0.8581 - val_loss: 0.5478\n",
      "Epoch 97/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.9107 - loss: 0.2860 - val_accuracy: 0.8705 - val_loss: 0.3625\n",
      "Epoch 98/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.9040 - loss: 0.2753 - val_accuracy: 0.7703 - val_loss: 0.7078\n",
      "Epoch 99/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.9032 - loss: 0.2827 - val_accuracy: 0.8549 - val_loss: 0.4631\n",
      "Epoch 100/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 113ms/step - accuracy: 0.9137 - loss: 0.2601 - val_accuracy: 0.8677 - val_loss: 0.5022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x34f3b3650>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "alexnet_model.fit(\n",
    "    x=train,\n",
    "    validation_data=valid,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831795e",
   "metadata": {},
   "source": [
    "#### Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9d0bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8671 - loss: 0.4777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5021674036979675, 0.8677471280097961]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_model.evaluate(valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
