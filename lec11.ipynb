{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc21e62b",
   "metadata": {},
   "source": [
    "## Глубокое обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e007fa",
   "metadata": {},
   "source": [
    "#### Инициализация Keras\n",
    "\n",
    "В качестве бэкенда используется jax\n",
    "\n",
    "Бэкенд должен указываться до импорта keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d88eddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725c3e2",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b2018b",
   "metadata": {},
   "source": [
    "#### Загрузка набора данных для задачи классификации\n",
    "\n",
    "База данных MNIST (сокращение от \"Modified National Institute of Standards and Technology\") — объёмная база данных образцов рукописного написания цифр. База данных является стандартом, предложенным Национальным институтом стандартов и технологий США с целью обучения и сопоставления методов распознавания изображений с помощью машинного обучения в первую очередь на основе нейронных сетей. Данные состоят из заранее подготовленных примеров изображений, на основе которых проводится обучение и тестирование систем.\n",
    "\n",
    "База данных MNIST содержит 60000 изображений для обучения и 10000 изображений для тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a770c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.api.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2231ce2",
   "metadata": {},
   "source": [
    "#### Отображение данных\n",
    "\n",
    "Образцы из набора прошли сглаживание и приведены к серому полутоновому изображению размером 28x28 пикселей.\n",
    "\n",
    "Под каждым изображением представлено соответствующее ему значение целевого признака (класс)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfd2770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(5, 5))\n",
    "for k in range(12):\n",
    "    current_axes = axes[k % 3][k % 4]\n",
    "    current_axes.imshow(X_train[k], cmap='grey')\n",
    "    current_axes.get_xaxis().set_ticks([])\n",
    "    current_axes.get_yaxis().set_ticks([])\n",
    "    current_axes.set_xlabel(y_train[k])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3639caf",
   "metadata": {},
   "source": [
    "#### Предобработка данных\n",
    "\n",
    "Количество классов - 10 (от 0 до 9).\n",
    "\n",
    "Все изображения из X трансформируются в векторы длиной 784 (28*28) признака и нормализуются.\n",
    "\n",
    "Для целевых признаков применяется унитарное кодирование в бинарные векторы длиной 10 (нормализация)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a696e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "\n",
    "X_train = X_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "X_valid = X_valid.reshape(10000, 784).astype(\"float32\") / 255\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, n_classes)\n",
    "\n",
    "display(X_train[0])\n",
    "display(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40173015",
   "metadata": {},
   "source": [
    "#### Проектирование архитектуры простой ИНС\n",
    "\n",
    "Сеть состоит из:\n",
    "- входного слоя с 784 входами (InputLayer);\n",
    "- скрытого полносвязного слоя с 64 sigmoid-нейронами (dense_2);\n",
    "- выходного слоя с 10 softmax-нейронами (многоклассовая классификация) (dense_3).\n",
    "\n",
    "Количество параметров в слоях:\n",
    "- dense_2: 784 * 64 + 64 = 50 176 + 64 = 50 240. У каждого из 64 нейронов 784 входа с 784 параметрами (w * x) + 64 смещения (b).\n",
    "- dense_3: 64 * 10 + 10 = 640 + 10 = 650.\n",
    "\n",
    "Всего параметров: 50 240 + 650 = 50 890.\n",
    "\n",
    "Все параметры настраиваются в процессе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b073d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dense, InputLayer\n",
    "\n",
    "simple_model = Sequential()\n",
    "simple_model.add(InputLayer(shape=(28*28,)))\n",
    "simple_model.add(Dense(64, activation=\"sigmoid\"))\n",
    "simple_model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21eb9e",
   "metadata": {},
   "source": [
    "#### Обучение простой модели\n",
    "\n",
    "Функция стоимости: MSE (квадратичная функция)\n",
    "\n",
    "Оптимизатор: стохастический градиентный спуск (SGD)\n",
    "\n",
    "Скорость обучения: 0.01\n",
    "\n",
    "Количество эпох: 200\n",
    "\n",
    "Размер пакета: 128\n",
    "\n",
    "Всего пакетов: 60 000 / 128 = 468.75 (468 пакетов по 128 изображений и 1 пакет с 96 изображениями)\n",
    "\n",
    "Метрика оценки качества: accuracy\n",
    "\n",
    "Оценка качества и стоимость на обучающей выборке:\\\n",
    "accuracy: 0.4650 - loss: 0.0849\n",
    "\n",
    "Оценка качества и стоимость на тестовой выборке:\\\n",
    "val_accuracy: 0.4703 - val_loss: 0.0845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65eca38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.0962 - loss: 0.0938 - val_accuracy: 0.0977 - val_loss: 0.0924\n",
      "Epoch 2/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0990 - loss: 0.0922 - val_accuracy: 0.1115 - val_loss: 0.0916\n",
      "Epoch 3/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1087 - loss: 0.0916 - val_accuracy: 0.1294 - val_loss: 0.0911\n",
      "Epoch 4/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1281 - loss: 0.0911 - val_accuracy: 0.1414 - val_loss: 0.0907\n",
      "Epoch 5/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1330 - loss: 0.0908 - val_accuracy: 0.1514 - val_loss: 0.0904\n",
      "Epoch 6/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1488 - loss: 0.0904 - val_accuracy: 0.1671 - val_loss: 0.0901\n",
      "Epoch 7/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1641 - loss: 0.0901 - val_accuracy: 0.1850 - val_loss: 0.0898\n",
      "Epoch 8/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1866 - loss: 0.0898 - val_accuracy: 0.2084 - val_loss: 0.0895\n",
      "Epoch 9/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2107 - loss: 0.0896 - val_accuracy: 0.2345 - val_loss: 0.0892\n",
      "Epoch 10/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2321 - loss: 0.0893 - val_accuracy: 0.2611 - val_loss: 0.0889\n",
      "Epoch 11/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2583 - loss: 0.0890 - val_accuracy: 0.2866 - val_loss: 0.0887\n",
      "Epoch 12/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2847 - loss: 0.0887 - val_accuracy: 0.3097 - val_loss: 0.0884\n",
      "Epoch 13/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3068 - loss: 0.0884 - val_accuracy: 0.3348 - val_loss: 0.0881\n",
      "Epoch 14/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3310 - loss: 0.0882 - val_accuracy: 0.3565 - val_loss: 0.0878\n",
      "Epoch 15/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3523 - loss: 0.0879 - val_accuracy: 0.3740 - val_loss: 0.0875\n",
      "Epoch 16/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3753 - loss: 0.0876 - val_accuracy: 0.3908 - val_loss: 0.0872\n",
      "Epoch 17/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3880 - loss: 0.0873 - val_accuracy: 0.4053 - val_loss: 0.0869\n",
      "Epoch 18/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4077 - loss: 0.0870 - val_accuracy: 0.4162 - val_loss: 0.0866\n",
      "Epoch 19/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4142 - loss: 0.0867 - val_accuracy: 0.4264 - val_loss: 0.0863\n",
      "Epoch 20/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4235 - loss: 0.0864 - val_accuracy: 0.4349 - val_loss: 0.0860\n",
      "Epoch 21/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4328 - loss: 0.0860 - val_accuracy: 0.4428 - val_loss: 0.0856\n",
      "Epoch 22/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4400 - loss: 0.0856 - val_accuracy: 0.4491 - val_loss: 0.0853\n",
      "Epoch 23/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4430 - loss: 0.0854 - val_accuracy: 0.4546 - val_loss: 0.0849\n",
      "Epoch 24/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4515 - loss: 0.0850 - val_accuracy: 0.4589 - val_loss: 0.0846\n",
      "Epoch 25/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4584 - loss: 0.0846 - val_accuracy: 0.4636 - val_loss: 0.0842\n",
      "Epoch 26/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4610 - loss: 0.0843 - val_accuracy: 0.4661 - val_loss: 0.0839\n",
      "Epoch 27/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4650 - loss: 0.0839 - val_accuracy: 0.4713 - val_loss: 0.0835\n",
      "Epoch 28/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4645 - loss: 0.0836 - val_accuracy: 0.4735 - val_loss: 0.0831\n",
      "Epoch 29/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4690 - loss: 0.0832 - val_accuracy: 0.4804 - val_loss: 0.0827\n",
      "Epoch 30/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4745 - loss: 0.0828 - val_accuracy: 0.4895 - val_loss: 0.0823\n",
      "Epoch 31/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4825 - loss: 0.0825 - val_accuracy: 0.5008 - val_loss: 0.0819\n",
      "Epoch 32/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4982 - loss: 0.0820 - val_accuracy: 0.5209 - val_loss: 0.0815\n",
      "Epoch 33/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5157 - loss: 0.0817 - val_accuracy: 0.5392 - val_loss: 0.0811\n",
      "Epoch 34/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5340 - loss: 0.0812 - val_accuracy: 0.5548 - val_loss: 0.0807\n",
      "Epoch 35/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5495 - loss: 0.0808 - val_accuracy: 0.5689 - val_loss: 0.0802\n",
      "Epoch 36/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5613 - loss: 0.0803 - val_accuracy: 0.5788 - val_loss: 0.0798\n",
      "Epoch 37/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5670 - loss: 0.0800 - val_accuracy: 0.5847 - val_loss: 0.0793\n",
      "Epoch 38/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5725 - loss: 0.0795 - val_accuracy: 0.5891 - val_loss: 0.0789\n",
      "Epoch 39/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5762 - loss: 0.0790 - val_accuracy: 0.5925 - val_loss: 0.0784\n",
      "Epoch 40/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5746 - loss: 0.0786 - val_accuracy: 0.5946 - val_loss: 0.0779\n",
      "Epoch 41/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5790 - loss: 0.0782 - val_accuracy: 0.5966 - val_loss: 0.0774\n",
      "Epoch 42/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5835 - loss: 0.0775 - val_accuracy: 0.5993 - val_loss: 0.0770\n",
      "Epoch 43/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5855 - loss: 0.0771 - val_accuracy: 0.6019 - val_loss: 0.0765\n",
      "Epoch 44/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5842 - loss: 0.0767 - val_accuracy: 0.6023 - val_loss: 0.0760\n",
      "Epoch 45/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5866 - loss: 0.0762 - val_accuracy: 0.6027 - val_loss: 0.0754\n",
      "Epoch 46/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5898 - loss: 0.0755 - val_accuracy: 0.6043 - val_loss: 0.0749\n",
      "Epoch 47/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5908 - loss: 0.0752 - val_accuracy: 0.6067 - val_loss: 0.0744\n",
      "Epoch 48/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5922 - loss: 0.0746 - val_accuracy: 0.6082 - val_loss: 0.0739\n",
      "Epoch 49/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5952 - loss: 0.0741 - val_accuracy: 0.6098 - val_loss: 0.0733\n",
      "Epoch 50/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5924 - loss: 0.0735 - val_accuracy: 0.6113 - val_loss: 0.0728\n",
      "Epoch 51/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5947 - loss: 0.0731 - val_accuracy: 0.6122 - val_loss: 0.0723\n",
      "Epoch 52/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5962 - loss: 0.0726 - val_accuracy: 0.6132 - val_loss: 0.0717\n",
      "Epoch 53/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6004 - loss: 0.0719 - val_accuracy: 0.6154 - val_loss: 0.0711\n",
      "Epoch 54/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6058 - loss: 0.0713 - val_accuracy: 0.6163 - val_loss: 0.0706\n",
      "Epoch 55/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6048 - loss: 0.0709 - val_accuracy: 0.6191 - val_loss: 0.0700\n",
      "Epoch 56/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6112 - loss: 0.0703 - val_accuracy: 0.6226 - val_loss: 0.0695\n",
      "Epoch 57/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6118 - loss: 0.0697 - val_accuracy: 0.6249 - val_loss: 0.0689\n",
      "Epoch 58/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6152 - loss: 0.0692 - val_accuracy: 0.6295 - val_loss: 0.0683\n",
      "Epoch 59/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6211 - loss: 0.0686 - val_accuracy: 0.6333 - val_loss: 0.0678\n",
      "Epoch 60/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6225 - loss: 0.0681 - val_accuracy: 0.6353 - val_loss: 0.0672\n",
      "Epoch 61/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6229 - loss: 0.0676 - val_accuracy: 0.6375 - val_loss: 0.0667\n",
      "Epoch 62/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6308 - loss: 0.0669 - val_accuracy: 0.6412 - val_loss: 0.0661\n",
      "Epoch 63/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6367 - loss: 0.0663 - val_accuracy: 0.6468 - val_loss: 0.0655\n",
      "Epoch 64/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6340 - loss: 0.0660 - val_accuracy: 0.6506 - val_loss: 0.0650\n",
      "Epoch 65/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6373 - loss: 0.0654 - val_accuracy: 0.6542 - val_loss: 0.0644\n",
      "Epoch 66/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6447 - loss: 0.0648 - val_accuracy: 0.6581 - val_loss: 0.0639\n",
      "Epoch 67/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6457 - loss: 0.0643 - val_accuracy: 0.6625 - val_loss: 0.0633\n",
      "Epoch 68/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6508 - loss: 0.0636 - val_accuracy: 0.6666 - val_loss: 0.0628\n",
      "Epoch 69/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6562 - loss: 0.0634 - val_accuracy: 0.6702 - val_loss: 0.0622\n",
      "Epoch 70/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6591 - loss: 0.0627 - val_accuracy: 0.6731 - val_loss: 0.0617\n",
      "Epoch 71/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6607 - loss: 0.0621 - val_accuracy: 0.6771 - val_loss: 0.0611\n",
      "Epoch 72/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6674 - loss: 0.0615 - val_accuracy: 0.6811 - val_loss: 0.0606\n",
      "Epoch 73/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6732 - loss: 0.0609 - val_accuracy: 0.6851 - val_loss: 0.0601\n",
      "Epoch 74/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6731 - loss: 0.0605 - val_accuracy: 0.6882 - val_loss: 0.0596\n",
      "Epoch 75/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6774 - loss: 0.0600 - val_accuracy: 0.6911 - val_loss: 0.0591\n",
      "Epoch 76/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6831 - loss: 0.0593 - val_accuracy: 0.6943 - val_loss: 0.0586\n",
      "Epoch 77/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6834 - loss: 0.0592 - val_accuracy: 0.6972 - val_loss: 0.0581\n",
      "Epoch 78/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6868 - loss: 0.0584 - val_accuracy: 0.7014 - val_loss: 0.0576\n",
      "Epoch 79/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6901 - loss: 0.0581 - val_accuracy: 0.7041 - val_loss: 0.0571\n",
      "Epoch 80/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6917 - loss: 0.0576 - val_accuracy: 0.7073 - val_loss: 0.0566\n",
      "Epoch 81/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6977 - loss: 0.0570 - val_accuracy: 0.7101 - val_loss: 0.0561\n",
      "Epoch 82/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7008 - loss: 0.0567 - val_accuracy: 0.7135 - val_loss: 0.0556\n",
      "Epoch 83/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7004 - loss: 0.0563 - val_accuracy: 0.7159 - val_loss: 0.0552\n",
      "Epoch 84/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7032 - loss: 0.0557 - val_accuracy: 0.7197 - val_loss: 0.0547\n",
      "Epoch 85/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7101 - loss: 0.0553 - val_accuracy: 0.7218 - val_loss: 0.0543\n",
      "Epoch 86/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7113 - loss: 0.0548 - val_accuracy: 0.7244 - val_loss: 0.0538\n",
      "Epoch 87/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7146 - loss: 0.0544 - val_accuracy: 0.7267 - val_loss: 0.0534\n",
      "Epoch 88/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7158 - loss: 0.0540 - val_accuracy: 0.7287 - val_loss: 0.0530\n",
      "Epoch 89/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7214 - loss: 0.0533 - val_accuracy: 0.7308 - val_loss: 0.0525\n",
      "Epoch 90/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7214 - loss: 0.0529 - val_accuracy: 0.7326 - val_loss: 0.0521\n",
      "Epoch 91/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7253 - loss: 0.0525 - val_accuracy: 0.7341 - val_loss: 0.0517\n",
      "Epoch 92/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7222 - loss: 0.0525 - val_accuracy: 0.7370 - val_loss: 0.0513\n",
      "Epoch 93/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7295 - loss: 0.0516 - val_accuracy: 0.7380 - val_loss: 0.0509\n",
      "Epoch 94/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7295 - loss: 0.0514 - val_accuracy: 0.7407 - val_loss: 0.0505\n",
      "Epoch 95/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7296 - loss: 0.0510 - val_accuracy: 0.7418 - val_loss: 0.0501\n",
      "Epoch 96/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7322 - loss: 0.0507 - val_accuracy: 0.7437 - val_loss: 0.0498\n",
      "Epoch 97/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7344 - loss: 0.0503 - val_accuracy: 0.7449 - val_loss: 0.0494\n",
      "Epoch 98/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7341 - loss: 0.0502 - val_accuracy: 0.7475 - val_loss: 0.0490\n",
      "Epoch 99/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.0497 - val_accuracy: 0.7487 - val_loss: 0.0486\n",
      "Epoch 100/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7407 - loss: 0.0492 - val_accuracy: 0.7500 - val_loss: 0.0483\n",
      "Epoch 101/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7383 - loss: 0.0491 - val_accuracy: 0.7513 - val_loss: 0.0479\n",
      "Epoch 102/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7422 - loss: 0.0485 - val_accuracy: 0.7533 - val_loss: 0.0476\n",
      "Epoch 103/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7457 - loss: 0.0482 - val_accuracy: 0.7550 - val_loss: 0.0473\n",
      "Epoch 104/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7442 - loss: 0.0479 - val_accuracy: 0.7561 - val_loss: 0.0469\n",
      "Epoch 105/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7479 - loss: 0.0475 - val_accuracy: 0.7577 - val_loss: 0.0466\n",
      "Epoch 106/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7482 - loss: 0.0473 - val_accuracy: 0.7590 - val_loss: 0.0463\n",
      "Epoch 107/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7516 - loss: 0.0468 - val_accuracy: 0.7604 - val_loss: 0.0460\n",
      "Epoch 108/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7524 - loss: 0.0467 - val_accuracy: 0.7617 - val_loss: 0.0457\n",
      "Epoch 109/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7553 - loss: 0.0461 - val_accuracy: 0.7637 - val_loss: 0.0453\n",
      "Epoch 110/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7518 - loss: 0.0460 - val_accuracy: 0.7650 - val_loss: 0.0450\n",
      "Epoch 111/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7540 - loss: 0.0459 - val_accuracy: 0.7657 - val_loss: 0.0447\n",
      "Epoch 112/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7540 - loss: 0.0456 - val_accuracy: 0.7667 - val_loss: 0.0445\n",
      "Epoch 113/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7555 - loss: 0.0453 - val_accuracy: 0.7672 - val_loss: 0.0442\n",
      "Epoch 114/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7572 - loss: 0.0451 - val_accuracy: 0.7678 - val_loss: 0.0439\n",
      "Epoch 115/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7587 - loss: 0.0447 - val_accuracy: 0.7689 - val_loss: 0.0436\n",
      "Epoch 116/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7602 - loss: 0.0444 - val_accuracy: 0.7697 - val_loss: 0.0433\n",
      "Epoch 117/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7603 - loss: 0.0441 - val_accuracy: 0.7701 - val_loss: 0.0431\n",
      "Epoch 118/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7610 - loss: 0.0440 - val_accuracy: 0.7707 - val_loss: 0.0428\n",
      "Epoch 119/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7637 - loss: 0.0437 - val_accuracy: 0.7717 - val_loss: 0.0425\n",
      "Epoch 120/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7630 - loss: 0.0433 - val_accuracy: 0.7724 - val_loss: 0.0423\n",
      "Epoch 121/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7656 - loss: 0.0430 - val_accuracy: 0.7731 - val_loss: 0.0420\n",
      "Epoch 122/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7674 - loss: 0.0429 - val_accuracy: 0.7736 - val_loss: 0.0418\n",
      "Epoch 123/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7655 - loss: 0.0427 - val_accuracy: 0.7746 - val_loss: 0.0415\n",
      "Epoch 124/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7687 - loss: 0.0422 - val_accuracy: 0.7761 - val_loss: 0.0413\n",
      "Epoch 125/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7701 - loss: 0.0420 - val_accuracy: 0.7773 - val_loss: 0.0410\n",
      "Epoch 126/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7700 - loss: 0.0417 - val_accuracy: 0.7786 - val_loss: 0.0408\n",
      "Epoch 127/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7699 - loss: 0.0415 - val_accuracy: 0.7791 - val_loss: 0.0406\n",
      "Epoch 128/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7717 - loss: 0.0411 - val_accuracy: 0.7796 - val_loss: 0.0403\n",
      "Epoch 129/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7690 - loss: 0.0413 - val_accuracy: 0.7800 - val_loss: 0.0401\n",
      "Epoch 130/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7707 - loss: 0.0411 - val_accuracy: 0.7806 - val_loss: 0.0399\n",
      "Epoch 131/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7714 - loss: 0.0409 - val_accuracy: 0.7812 - val_loss: 0.0396\n",
      "Epoch 132/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7742 - loss: 0.0403 - val_accuracy: 0.7818 - val_loss: 0.0394\n",
      "Epoch 133/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7731 - loss: 0.0404 - val_accuracy: 0.7820 - val_loss: 0.0392\n",
      "Epoch 134/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7771 - loss: 0.0398 - val_accuracy: 0.7827 - val_loss: 0.0390\n",
      "Epoch 135/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7732 - loss: 0.0400 - val_accuracy: 0.7832 - val_loss: 0.0388\n",
      "Epoch 136/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7745 - loss: 0.0397 - val_accuracy: 0.7841 - val_loss: 0.0386\n",
      "Epoch 137/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7764 - loss: 0.0394 - val_accuracy: 0.7855 - val_loss: 0.0383\n",
      "Epoch 138/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7791 - loss: 0.0392 - val_accuracy: 0.7866 - val_loss: 0.0381\n",
      "Epoch 139/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7790 - loss: 0.0392 - val_accuracy: 0.7888 - val_loss: 0.0379\n",
      "Epoch 140/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7812 - loss: 0.0387 - val_accuracy: 0.7896 - val_loss: 0.0377\n",
      "Epoch 141/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7792 - loss: 0.0387 - val_accuracy: 0.7904 - val_loss: 0.0375\n",
      "Epoch 142/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7818 - loss: 0.0383 - val_accuracy: 0.7918 - val_loss: 0.0373\n",
      "Epoch 143/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7832 - loss: 0.0383 - val_accuracy: 0.7929 - val_loss: 0.0371\n",
      "Epoch 144/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7848 - loss: 0.0380 - val_accuracy: 0.7947 - val_loss: 0.0369\n",
      "Epoch 145/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7836 - loss: 0.0379 - val_accuracy: 0.7961 - val_loss: 0.0367\n",
      "Epoch 146/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7872 - loss: 0.0377 - val_accuracy: 0.7972 - val_loss: 0.0365\n",
      "Epoch 147/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7865 - loss: 0.0375 - val_accuracy: 0.7986 - val_loss: 0.0363\n",
      "Epoch 148/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7923 - loss: 0.0370 - val_accuracy: 0.8002 - val_loss: 0.0361\n",
      "Epoch 149/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7916 - loss: 0.0371 - val_accuracy: 0.8015 - val_loss: 0.0360\n",
      "Epoch 150/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7935 - loss: 0.0368 - val_accuracy: 0.8028 - val_loss: 0.0358\n",
      "Epoch 151/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7967 - loss: 0.0366 - val_accuracy: 0.8052 - val_loss: 0.0356\n",
      "Epoch 152/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7987 - loss: 0.0365 - val_accuracy: 0.8063 - val_loss: 0.0354\n",
      "Epoch 153/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7956 - loss: 0.0365 - val_accuracy: 0.8079 - val_loss: 0.0352\n",
      "Epoch 154/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7995 - loss: 0.0361 - val_accuracy: 0.8096 - val_loss: 0.0350\n",
      "Epoch 155/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8021 - loss: 0.0361 - val_accuracy: 0.8121 - val_loss: 0.0349\n",
      "Epoch 156/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8043 - loss: 0.0357 - val_accuracy: 0.8131 - val_loss: 0.0347\n",
      "Epoch 157/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8040 - loss: 0.0358 - val_accuracy: 0.8148 - val_loss: 0.0345\n",
      "Epoch 158/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.0352 - val_accuracy: 0.8161 - val_loss: 0.0343\n",
      "Epoch 159/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8082 - loss: 0.0354 - val_accuracy: 0.8180 - val_loss: 0.0342\n",
      "Epoch 160/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8107 - loss: 0.0350 - val_accuracy: 0.8190 - val_loss: 0.0340\n",
      "Epoch 161/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8109 - loss: 0.0350 - val_accuracy: 0.8207 - val_loss: 0.0338\n",
      "Epoch 162/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8118 - loss: 0.0349 - val_accuracy: 0.8220 - val_loss: 0.0336\n",
      "Epoch 163/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8133 - loss: 0.0346 - val_accuracy: 0.8234 - val_loss: 0.0335\n",
      "Epoch 164/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8157 - loss: 0.0344 - val_accuracy: 0.8245 - val_loss: 0.0333\n",
      "Epoch 165/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8165 - loss: 0.0343 - val_accuracy: 0.8259 - val_loss: 0.0331\n",
      "Epoch 166/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8183 - loss: 0.0340 - val_accuracy: 0.8269 - val_loss: 0.0330\n",
      "Epoch 167/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8186 - loss: 0.0340 - val_accuracy: 0.8282 - val_loss: 0.0328\n",
      "Epoch 168/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8204 - loss: 0.0337 - val_accuracy: 0.8301 - val_loss: 0.0327\n",
      "Epoch 169/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8229 - loss: 0.0336 - val_accuracy: 0.8307 - val_loss: 0.0325\n",
      "Epoch 170/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8245 - loss: 0.0332 - val_accuracy: 0.8320 - val_loss: 0.0323\n",
      "Epoch 171/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8264 - loss: 0.0330 - val_accuracy: 0.8321 - val_loss: 0.0322\n",
      "Epoch 172/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8237 - loss: 0.0333 - val_accuracy: 0.8333 - val_loss: 0.0320\n",
      "Epoch 173/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8234 - loss: 0.0331 - val_accuracy: 0.8346 - val_loss: 0.0319\n",
      "Epoch 174/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8264 - loss: 0.0329 - val_accuracy: 0.8353 - val_loss: 0.0317\n",
      "Epoch 175/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8281 - loss: 0.0326 - val_accuracy: 0.8362 - val_loss: 0.0316\n",
      "Epoch 176/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8287 - loss: 0.0326 - val_accuracy: 0.8374 - val_loss: 0.0314\n",
      "Epoch 177/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8304 - loss: 0.0324 - val_accuracy: 0.8383 - val_loss: 0.0313\n",
      "Epoch 178/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8313 - loss: 0.0323 - val_accuracy: 0.8392 - val_loss: 0.0311\n",
      "Epoch 179/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8330 - loss: 0.0322 - val_accuracy: 0.8401 - val_loss: 0.0310\n",
      "Epoch 180/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8336 - loss: 0.0319 - val_accuracy: 0.8413 - val_loss: 0.0308\n",
      "Epoch 181/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8372 - loss: 0.0317 - val_accuracy: 0.8424 - val_loss: 0.0307\n",
      "Epoch 182/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8355 - loss: 0.0318 - val_accuracy: 0.8433 - val_loss: 0.0306\n",
      "Epoch 183/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8393 - loss: 0.0313 - val_accuracy: 0.8443 - val_loss: 0.0304\n",
      "Epoch 184/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8384 - loss: 0.0315 - val_accuracy: 0.8449 - val_loss: 0.0303\n",
      "Epoch 185/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8380 - loss: 0.0313 - val_accuracy: 0.8458 - val_loss: 0.0301\n",
      "Epoch 186/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8384 - loss: 0.0313 - val_accuracy: 0.8466 - val_loss: 0.0300\n",
      "Epoch 187/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8393 - loss: 0.0310 - val_accuracy: 0.8475 - val_loss: 0.0299\n",
      "Epoch 188/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8423 - loss: 0.0307 - val_accuracy: 0.8481 - val_loss: 0.0297\n",
      "Epoch 189/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8408 - loss: 0.0308 - val_accuracy: 0.8486 - val_loss: 0.0296\n",
      "Epoch 190/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8433 - loss: 0.0307 - val_accuracy: 0.8493 - val_loss: 0.0295\n",
      "Epoch 191/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8415 - loss: 0.0306 - val_accuracy: 0.8506 - val_loss: 0.0294\n",
      "Epoch 192/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 0.0302 - val_accuracy: 0.8508 - val_loss: 0.0292\n",
      "Epoch 193/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8454 - loss: 0.0301 - val_accuracy: 0.8517 - val_loss: 0.0291\n",
      "Epoch 194/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 0.0301 - val_accuracy: 0.8524 - val_loss: 0.0290\n",
      "Epoch 195/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8453 - loss: 0.0301 - val_accuracy: 0.8530 - val_loss: 0.0288\n",
      "Epoch 196/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8463 - loss: 0.0300 - val_accuracy: 0.8537 - val_loss: 0.0287\n",
      "Epoch 197/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8473 - loss: 0.0297 - val_accuracy: 0.8546 - val_loss: 0.0286\n",
      "Epoch 198/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8484 - loss: 0.0297 - val_accuracy: 0.8555 - val_loss: 0.0285\n",
      "Epoch 199/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8503 - loss: 0.0293 - val_accuracy: 0.8558 - val_loss: 0.0284\n",
      "Epoch 200/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 0.0296 - val_accuracy: 0.8561 - val_loss: 0.0282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2656ebea120>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.api.optimizers import SGD\n",
    "\n",
    "simple_model.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    optimizer=SGD(learning_rate=0.01),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "simple_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=200,\n",
    "    validation_data=(X_valid, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20501a84",
   "metadata": {},
   "source": [
    "#### Оценка качества простой модели\n",
    "\n",
    "Лучшее качество модели: 85.61 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30db9b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.0311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.028248243033885956, 0.8561000227928162]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db127c8",
   "metadata": {},
   "source": [
    "#### Проектирование архитектуры более сложной ИНС\n",
    "\n",
    "Добавлен дополнительный скрытый полносвязный слой\n",
    "\n",
    "Все скрытые слои используют ReLU-нейроны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2f2c585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,050</span> (215.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,050\u001b[0m (215.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,050</span> (215.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,050\u001b[0m (215.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "difficult_model = Sequential()\n",
    "difficult_model.add(InputLayer(shape=(28 * 28,)))\n",
    "difficult_model.add(Dense(64, activation=\"relu\"))\n",
    "difficult_model.add(Dense(64, activation=\"relu\"))\n",
    "difficult_model.add(Dense(10, activation=\"softmax\"))\n",
    "difficult_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5650eddc",
   "metadata": {},
   "source": [
    "#### Обучение более сложной модели\n",
    "\n",
    "Функция стоимости изменена на перекрестную энтропию (лучше подходит для классификации)\n",
    "\n",
    "Количество эпох уменьшено с 200 до 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10fc0413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7741 - loss: 0.7852 - val_accuracy: 0.9121 - val_loss: 0.2913\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9271 - loss: 0.2477 - val_accuracy: 0.9416 - val_loss: 0.1966\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9452 - loss: 0.1852 - val_accuracy: 0.9541 - val_loss: 0.1530\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9567 - loss: 0.1534 - val_accuracy: 0.9559 - val_loss: 0.1484\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9645 - loss: 0.1249 - val_accuracy: 0.9609 - val_loss: 0.1264\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9686 - loss: 0.1080 - val_accuracy: 0.9665 - val_loss: 0.1091\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9717 - loss: 0.0960 - val_accuracy: 0.9670 - val_loss: 0.1078\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9744 - loss: 0.0882 - val_accuracy: 0.9706 - val_loss: 0.1011\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9773 - loss: 0.0787 - val_accuracy: 0.9714 - val_loss: 0.0944\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.0681 - val_accuracy: 0.9711 - val_loss: 0.0944\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0632 - val_accuracy: 0.9726 - val_loss: 0.0865\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0608 - val_accuracy: 0.9718 - val_loss: 0.0919\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0519 - val_accuracy: 0.9711 - val_loss: 0.0909\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0508 - val_accuracy: 0.9753 - val_loss: 0.0825\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0445 - val_accuracy: 0.9749 - val_loss: 0.0840\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0438 - val_accuracy: 0.9741 - val_loss: 0.0802\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0378 - val_accuracy: 0.9764 - val_loss: 0.0802\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0358 - val_accuracy: 0.9760 - val_loss: 0.0834\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0333 - val_accuracy: 0.9733 - val_loss: 0.0873\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0311 - val_accuracy: 0.9762 - val_loss: 0.0795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2656ec93380>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difficult_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=SGD(learning_rate=0.1),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "difficult_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    validation_data=(X_valid, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2db19",
   "metadata": {},
   "source": [
    "#### Оценка качества более сложной модели\n",
    "\n",
    "Лучшее качество модели: 97.61 %\n",
    "\n",
    "При этом количество эпох обучения значительно сократилось (с 200 до 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df92dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9720 - loss: 0.0956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07949920743703842, 0.9761999845504761]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difficult_model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768404ed",
   "metadata": {},
   "source": [
    "#### Проектирование архитектуры глубокой ИНС\n",
    "\n",
    "В ИНС теперь три скрытых полносвязных слоя с ReLU-нейронами\n",
    "\n",
    "Для выходов каждого скрытого слоя используется пакетная нормализация\n",
    "\n",
    "Для последнего скрытого слоя применяется прореживание, при котором отключается 20 % случайных нейронов\n",
    "\n",
    "Keras автоматически корректирует значения (умножает входы на 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddbbb225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,978</span> (234.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m59,978\u001b[0m (234.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,594</span> (232.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m59,594\u001b[0m (232.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.api.layers import Dropout\n",
    "from keras.api.layers import BatchNormalization\n",
    "\n",
    "deep_model = Sequential()\n",
    "deep_model.add(InputLayer(shape=(28 * 28,)))\n",
    "deep_model.add(Dense(64, activation=\"relu\"))\n",
    "deep_model.add(BatchNormalization())\n",
    "deep_model.add(Dense(64, activation=\"relu\"))\n",
    "deep_model.add(BatchNormalization())\n",
    "deep_model.add(Dense(64, activation=\"relu\"))\n",
    "deep_model.add(BatchNormalization())\n",
    "deep_model.add(Dropout(0.2))\n",
    "deep_model.add(Dense(10, activation=\"softmax\"))\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985823c3",
   "metadata": {},
   "source": [
    "#### Обучение глубокой модели\n",
    "\n",
    "Вместо SGD используется оптимизатор Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f0f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7853 - loss: 0.7060 - val_accuracy: 0.9503 - val_loss: 0.1622\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9547 - loss: 0.1525 - val_accuracy: 0.9643 - val_loss: 0.1198\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9641 - loss: 0.1140 - val_accuracy: 0.9684 - val_loss: 0.1098\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9723 - loss: 0.0914 - val_accuracy: 0.9709 - val_loss: 0.0952\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9771 - loss: 0.0719 - val_accuracy: 0.9720 - val_loss: 0.0983\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9786 - loss: 0.0675 - val_accuracy: 0.9757 - val_loss: 0.0823\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9835 - loss: 0.0527 - val_accuracy: 0.9734 - val_loss: 0.0912\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9838 - loss: 0.0493 - val_accuracy: 0.9721 - val_loss: 0.0969\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9852 - loss: 0.0447 - val_accuracy: 0.9728 - val_loss: 0.0965\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9864 - loss: 0.0415 - val_accuracy: 0.9742 - val_loss: 0.0944\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9885 - loss: 0.0346 - val_accuracy: 0.9748 - val_loss: 0.0976\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9886 - loss: 0.0332 - val_accuracy: 0.9735 - val_loss: 0.0935\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9892 - loss: 0.0315 - val_accuracy: 0.9731 - val_loss: 0.0984\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9889 - loss: 0.0321 - val_accuracy: 0.9757 - val_loss: 0.0923\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9905 - loss: 0.0273 - val_accuracy: 0.9724 - val_loss: 0.1016\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9924 - loss: 0.0240 - val_accuracy: 0.9729 - val_loss: 0.0980\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0223 - val_accuracy: 0.9774 - val_loss: 0.0975\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.0211 - val_accuracy: 0.9763 - val_loss: 0.0949\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.9922 - loss: 0.0228 - val_accuracy: 0.9756 - val_loss: 0.0985\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9939 - loss: 0.0180 - val_accuracy: 0.9744 - val_loss: 0.1107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2657dda7860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    validation_data=(X_valid, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc87962",
   "metadata": {},
   "source": [
    "#### Оценка качества глубокой модели\n",
    "\n",
    "Лучшее качество модели: 97.44 %\n",
    "\n",
    "Качество модели незначительно улучшилось за счет улучшения архитектуры сети и смены оптимизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70d626e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9693 - loss: 0.1362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11072272062301636, 0.974399983882904]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc09e059",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cfb72f",
   "metadata": {},
   "source": [
    "#### Загрузка данных для задачи регрессии\n",
    "\n",
    "Набор данных о жилье в Бостоне собран Службой переписи населения США.\n",
    "\n",
    "Входные признаки:\n",
    "- CRIM — уровень преступности на душу населения по районам;\n",
    "- ZN — доля жилых земель, отведенных под участки площадью более 25 000 кв. футов;\n",
    "- INDUS — доля неторговых акров в городе;\n",
    "- CHAS — 1, если участок граничит с рекой; 0 в противном случае;\n",
    "- NOX — концентрация оксидов азота;\n",
    "- RM — среднее количество комнат в помещении;\n",
    "- AGE — доля домов, построенных до 1940 года;\n",
    "- DIS — взвешенные расстояния до пяти центров занятости Бостона;\n",
    "- RAD — индекс доступности радиальных автомагистралей;\n",
    "- TAX — ставка налога на имущество на полную стоимость;\n",
    "- PTRATIO — соотношение учеников и учителей по районам;\n",
    "- B — доля чернокожих по районам;\n",
    "- LSTAT — % населения с более низким статусом.\n",
    "\n",
    "Целевой признак:\n",
    "- MEDV — медианная стоимость домов в тысячах долларов США.\n",
    "\n",
    "Данные уже предобработаны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23146b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
       "        3.96900e+02, 1.87200e+01],\n",
       "       [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
       "        3.95380e+02, 3.11000e+00],\n",
       "       [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        3.75520e+02, 3.26000e+00],\n",
       "       ...,\n",
       "       [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
       "        3.62250e+02, 7.83000e+00],\n",
       "       [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        2.61950e+02, 1.57900e+01],\n",
       "       [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
       "        3.76700e+02, 4.38000e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.api.datasets import boston_housing\n",
    "\n",
    "(X_train, y_train), (X_valid, y_valid) = boston_housing.load_data()\n",
    "\n",
    "display(X_train)\n",
    "display(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59b0ae",
   "metadata": {},
   "source": [
    "#### Проектирование ИНС для задачи регрессии\n",
    "\n",
    "Для решения задачи регрессии в выходном слое используются нейроны с линейной функцией активации\n",
    "\n",
    "Создавать более сложную архитектуру не имеет смысла, так как в наборе данных мало признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ebaf129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,185</span> (4.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,185\u001b[0m (4.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,089</span> (4.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,089\u001b[0m (4.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> (384.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m96\u001b[0m (384.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_model = Sequential()\n",
    "reg_model.add(InputLayer(shape=(13,)))\n",
    "reg_model.add(Dense(32, activation=\"relu\"))\n",
    "reg_model.add(BatchNormalization())\n",
    "reg_model.add(Dense(16, activation=\"relu\"))\n",
    "reg_model.add(BatchNormalization())\n",
    "reg_model.add(Dropout(0.2))\n",
    "reg_model.add(Dense(1, activation=\"linear\"))\n",
    "reg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474627ee",
   "metadata": {},
   "source": [
    "#### Обучение модели для регрессии\n",
    "\n",
    "Функция стоимости: MSE (лучше подходит для задачи регрессии)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b1a0038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 555.4380 - val_loss: 818.1764\n",
      "Epoch 2/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 560.5256 - val_loss: 696.0439\n",
      "Epoch 3/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 533.2505 - val_loss: 606.2534\n",
      "Epoch 4/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 482.1046 - val_loss: 552.3464\n",
      "Epoch 5/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 472.9739 - val_loss: 505.9425\n",
      "Epoch 6/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 452.0256 - val_loss: 493.6840\n",
      "Epoch 7/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 442.5248 - val_loss: 437.7192\n",
      "Epoch 8/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 417.7417 - val_loss: 393.0793\n",
      "Epoch 9/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 385.2766 - val_loss: 355.9293\n",
      "Epoch 10/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 346.3936 - val_loss: 281.8849\n",
      "Epoch 11/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 275.4567 - val_loss: 213.9442\n",
      "Epoch 12/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 255.8001 - val_loss: 194.8567\n",
      "Epoch 13/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 219.8077 - val_loss: 226.2605\n",
      "Epoch 14/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 180.0764 - val_loss: 217.2234\n",
      "Epoch 15/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 145.8978 - val_loss: 119.7777\n",
      "Epoch 16/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 114.9447 - val_loss: 146.9448\n",
      "Epoch 17/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 90.5980 - val_loss: 56.1247\n",
      "Epoch 18/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 78.5159 - val_loss: 81.2109\n",
      "Epoch 19/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 66.1302 - val_loss: 86.8845\n",
      "Epoch 20/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 65.7594 - val_loss: 81.8400\n",
      "Epoch 21/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 56.4082 - val_loss: 61.9716\n",
      "Epoch 22/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 50.8065 - val_loss: 46.4101\n",
      "Epoch 23/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 52.3661 - val_loss: 35.3730\n",
      "Epoch 24/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 51.1238 - val_loss: 38.9305\n",
      "Epoch 25/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 41.3360 - val_loss: 33.8871\n",
      "Epoch 26/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 44.0401 - val_loss: 40.6093\n",
      "Epoch 27/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 44.4952 - val_loss: 44.3653\n",
      "Epoch 28/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 51.3225 - val_loss: 35.4017\n",
      "Epoch 29/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 40.8919 - val_loss: 36.6961\n",
      "Epoch 30/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 38.8680 - val_loss: 40.2563\n",
      "Epoch 31/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 39.6865 - val_loss: 33.4025\n",
      "Epoch 32/32\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 43.1028 - val_loss: 37.3483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2658a34e6f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.compile(\n",
    "    loss=\"mean_squared_error\",\n",
    "    optimizer=\"adam\",\n",
    ")\n",
    "\n",
    "reg_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=8,\n",
    "    epochs=32,\n",
    "    validation_data=(X_valid, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb962af9",
   "metadata": {},
   "source": [
    "#### Оценка качества модели для регрессии\n",
    "\n",
    "Средняя ошибка на тестовой выборке: 37.34 тысячи долларов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "727e9df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.775257"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "14.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_hat = reg_model.predict(np.reshape(X_valid[42], [1, 13]))\n",
    "display(y_hat[0][0])\n",
    "display(y_valid[42])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
